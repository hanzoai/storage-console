"use strict";(self.webpackChunkweb_app=self.webpackChunkweb_app||[]).push([[610],{6610:(e,n,t)=>{t.r(n),t.d(n,{default:()=>T});var i=t(5043),s=t(579);const o="#09090b",a="#111113",r="#fafafa",c="#a1a1aa",l="#71717a",d="#fd4444",h="rgba(253, 68, 68, 0.12)",p="#0c0c0e",u="rgba(255,255,255,0.06)",m="'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif",g="'Geist Mono', 'SF Mono', 'Fira Code', 'Cascadia Code', monospace",b=e=>{let{size:n=28}=e;return(0,s.jsxs)("svg",{width:n,height:n,viewBox:"0 0 64 64",fill:"none",xmlns:"http://www.w3.org/2000/svg",children:[(0,s.jsx)("rect",{width:"64",height:"64",rx:"8",fill:"#000000"}),(0,s.jsxs)("g",{transform:"translate(8, 8) scale(0.716)",children:[(0,s.jsx)("path",{d:"M22.21 67V44.6369H0V67H22.21Z",fill:"#ffffff"}),(0,s.jsx)("path",{d:"M66.7038 22.3184H22.2534L0.0878906 44.6367H44.4634L66.7038 22.3184Z",fill:"#ffffff"}),(0,s.jsx)("path",{d:"M22.21 0H0V22.3184H22.21V0Z",fill:"#ffffff"}),(0,s.jsx)("path",{d:"M66.7198 0H44.5098V22.3184H66.7198V0Z",fill:"#ffffff"}),(0,s.jsx)("path",{d:"M66.7198 67V44.6369H44.5098V67H66.7198Z",fill:"#ffffff"})]})]})},y={fontFamily:g,fontSize:12,color:r,backgroundColor:p,padding:"2px 6px",borderRadius:4},f=e=>{let{children:n,title:t}=e;return(0,s.jsxs)("div",{style:{margin:"16px 0"},children:[(0,s.jsxs)("div",{style:{display:"flex",alignItems:"center",justifyContent:"space-between",padding:"6px 14px",backgroundColor:"rgba(255,255,255,0.03)",borderTopLeftRadius:8,borderTopRightRadius:8,border:`1px solid ${u}`,borderBottom:"none"},children:[(0,s.jsx)("span",{style:{fontSize:11,fontWeight:600,color:l,textTransform:"uppercase",letterSpacing:"0.05em"},children:t||"code"}),(0,s.jsx)("span",{style:{fontSize:11,color:l,cursor:"pointer",padding:"2px 8px",borderRadius:4,border:`1px solid ${u}`,userSelect:"none"},children:"Copy"})]}),(0,s.jsx)("pre",{style:{margin:0,padding:"16px 20px",backgroundColor:p,borderBottomLeftRadius:8,borderBottomRightRadius:8,border:`1px solid ${u}`,fontSize:13,lineHeight:1.7,overflow:"auto",color:c,fontFamily:g,whiteSpace:"pre-wrap",wordBreak:"break-word"},children:n})]})},x=e=>{let{type:n,children:t}=e;const i="warning"===n?"rgba(250,204,21,0.06)":"tip"===n?"rgba(34,197,94,0.06)":h,o="warning"===n?"rgba(250,204,21,0.2)":"tip"===n?"rgba(34,197,94,0.2)":"rgba(253,68,68,0.2)",a="warning"===n?"Warning":"tip"===n?"Tip":"Note";return(0,s.jsxs)("div",{style:{margin:"16px 0",padding:"14px 18px",backgroundColor:i,border:`1px solid ${o}`,borderRadius:8,fontSize:13,lineHeight:1.7,color:c},children:[(0,s.jsx)("strong",{style:{color:r,fontSize:12,textTransform:"uppercase",letterSpacing:"0.04em"},children:a}),(0,s.jsx)("div",{style:{marginTop:6},children:t})]})},S=e=>{let{headers:n,rows:t}=e;return(0,s.jsx)("div",{style:{margin:"16px 0",overflowX:"auto"},children:(0,s.jsxs)("table",{style:{width:"100%",borderCollapse:"collapse",fontSize:13},children:[(0,s.jsx)("thead",{children:(0,s.jsx)("tr",{children:n.map((e=>(0,s.jsx)("th",{style:{textAlign:"left",padding:"10px 14px",borderBottom:`1px solid ${u}`,color:r,fontWeight:600,fontSize:12},children:e},e)))})}),(0,s.jsx)("tbody",{children:t.map(((e,n)=>(0,s.jsx)("tr",{children:e.map(((e,n)=>(0,s.jsx)("td",{style:{padding:"10px 14px",borderBottom:`1px solid ${u}`,color:c,fontFamily:0===n?g:m,fontSize:0===n?12:13},children:e},n)))},n)))})]})})},j={quickstart:{label:"GETTING STARTED",color:"#22c55e"},"console-overview":{label:"CONSOLE GUIDE",color:"#3b82f6"},"s3-compatibility":{label:"S3 API",color:"#a855f7"},"sdk-javascript":{label:"SDKs & TOOLS",color:"#f59e0b"},"auth-oidc":{label:"SECURITY",color:"#ef4444"},"admin-config":{label:"ADMINISTRATION",color:"#06b6d4"},"ops-erasure-coding":{label:"OPERATIONS",color:"#ec4899"}},k=e=>{let{id:n,children:t}=e;const i=j[n];return(0,s.jsxs)("div",{style:{marginTop:64,paddingTop:24,borderTop:`1px solid ${u}`},children:[i&&(0,s.jsx)("span",{style:{display:"inline-block",fontSize:10,fontWeight:700,letterSpacing:"0.08em",color:i.color,backgroundColor:`${i.color}14`,border:`1px solid ${i.color}30`,borderRadius:100,padding:"3px 10px",marginBottom:12},children:i.label}),(0,s.jsx)("h2",{id:n,style:{fontSize:22,fontWeight:700,letterSpacing:"-0.03em",margin:"0 0 16px",color:r},children:t})]})},_=e=>{let{id:n,children:t}=e;return(0,s.jsx)("h3",{id:n,style:{fontSize:17,fontWeight:600,letterSpacing:"-0.02em",margin:"32px 0 12px",color:r},children:t})},v=e=>{let{children:n}=e;return(0,s.jsx)("p",{style:{fontSize:14,lineHeight:1.75,color:c,margin:"12px 0"},children:n})},E={"operations/troubleshooting":"ops-troubleshooting","administration/identity-access-management":"auth-iam","administration/identity-access-management/policy-based-access-control":"auth-iam","administration/identity-access-management/oidc-access-management":"auth-oidc","administration/identity-access-management/ldap-access-management":"auth-ldap","administration/object-management":"console-objects","administration/object-management/object-versioning":"admin-versioning","administration/object-management/object-retention":"ops-locking","administration/bucket-replication":"admin-replication","administration/bucket-notifications":"admin-notifications","administration/monitoring":"console-monitoring","administration/server-side-encryption":"auth-encryption","operations/install-deploy-manage/deploy-minio/deploy-minio-single-node-single-drive":"single-node","operations/install-deploy-manage/deploy-minio/deploy-minio-single-node-multi-drive":"single-node-multi-drive","operations/install-deploy-manage/deploy-minio/deploy-minio-multi-node-multi-drive":"deploy-distributed","operations/monitoring":"ops-metrics","operations/server-side-encryption":"auth-encryption","operations/data-recovery":"ops-recovery","operations/network-encryption":"ops-tls","operations/concepts/erasure-coding":"ops-erasure-coding","operations/concepts/healing":"ops-healing","operations/scaling":"ops-scaling","operations/decommissioning":"ops-scaling","operations/manage-existing-deployments/migrate-fs-gateway":"admin-config","operations/install-deploy-manage/upgrade-minio-deployment":"ops-upgrade","integrations/event-notifications/event-notification-targets/publish-events-to-webhook":"admin-notifications","integrations/event-notifications/event-notification-targets/publish-events-to-kafka":"admin-notifications","integrations/event-notifications/event-notification-targets/publish-events-to-amqp":"admin-notifications","integrations/event-notifications/event-notification-targets/publish-events-to-redis":"admin-notifications","integrations/event-notifications/event-notification-targets/publish-events-to-postgresql":"admin-notifications","integrations/event-notifications/event-notification-targets/publish-events-to-elasticsearch":"admin-notifications","integrations/event-notifications/event-notification-targets/publish-events-to-nats":"admin-notifications","administration/batch-framework":"ops-batch","administration/object-management/transition-objects-to-a-remote-tier":"admin-tiering","secure-hybrid-cloud-storage-iam":"auth-oidc","kafka-and-storage":"admin-notifications","supportability-storage-chain":"ops-troubleshooting","regulatory-compliance-with-object-lambdas":"ops-locking"},w=[{title:"Getting Started",items:[{id:"quickstart",label:"Quick Start"},{id:"deploy-docker",label:"Deploy with Docker"},{id:"deploy-binary",label:"Deploy Binary"},{id:"deploy-kubernetes",label:"Deploy on Kubernetes"},{id:"deploy-distributed",label:"Distributed Deployment"},{id:"first-steps",label:"First Steps"}]},{title:"Console Guide",items:[{id:"console-overview",label:"Overview"},{id:"console-buckets",label:"Managing Buckets"},{id:"console-objects",label:"Browsing Objects"},{id:"console-access",label:"Access Keys"},{id:"console-monitoring",label:"Monitoring"}]},{title:"S3 API",items:[{id:"s3-compatibility",label:"S3 Compatibility"},{id:"s3-buckets",label:"Bucket Operations"},{id:"s3-objects",label:"Object Operations"},{id:"s3-presigned",label:"Presigned URLs"},{id:"s3-multipart",label:"Multipart Upload"}]},{title:"SDKs & Tools",items:[{id:"sdk-javascript",label:"JavaScript"},{id:"sdk-python",label:"Python"},{id:"sdk-go",label:"Go"},{id:"sdk-java",label:"Java"},{id:"sdk-cli",label:"s3 CLI"},{id:"sdk-cli-admin",label:"s3 Admin"},{id:"sdk-aws",label:"AWS CLI"}]},{title:"Security",items:[{id:"auth-oidc",label:"OIDC / SSO"},{id:"auth-ldap",label:"LDAP / Active Directory"},{id:"auth-iam",label:"IAM Policies"},{id:"auth-encryption",label:"Encryption"},{id:"auth-bucket-policy",label:"Bucket Policies"}]},{title:"Administration",items:[{id:"admin-config",label:"Server Configuration"},{id:"admin-lifecycle",label:"Lifecycle Rules"},{id:"admin-tiering",label:"Tiering & Transitions"},{id:"admin-replication",label:"Replication"},{id:"admin-notifications",label:"Event Notifications"},{id:"admin-versioning",label:"Versioning"}]},{title:"Operations",items:[{id:"ops-erasure-coding",label:"Erasure Coding"},{id:"ops-healing",label:"Healing"},{id:"ops-locking",label:"Object Locking / WORM"},{id:"ops-metrics",label:"Metrics & Monitoring"},{id:"ops-tls",label:"TLS / Network Encryption"},{id:"ops-scaling",label:"Scaling & Expansion"},{id:"ops-upgrade",label:"Upgrade Procedures"},{id:"ops-batch",label:"Batch Operations"},{id:"ops-recovery",label:"Data Recovery"},{id:"ops-troubleshooting",label:"Troubleshooting"},{id:"ops-healthcheck",label:"Health Check API"}]}],O=()=>(0,s.jsxs)("div",{children:[(0,s.jsx)(k,{id:"quickstart",children:"Quick Start"}),(0,s.jsxs)("div",{style:{backgroundColor:a,borderRadius:12,padding:"20px 24px",marginBottom:8,border:`1px solid ${u}`},children:[(0,s.jsx)(v,{children:"Hanzo Space is a high-performance, S3-compatible object storage system. It runs as a single binary, supports distributed deployments with erasure coding, and is fully compatible with the Amazon S3 API. All existing S3 tools, SDKs, and integrations work out of the box."}),(0,s.jsx)(v,{children:"The fastest way to get started is with Docker:"}),(0,s.jsx)(f,{title:"Docker \u2014 single node",children:'docker run -d --name hanzo-space \\\n  -p 9000:9000 -p 9001:9001 \\\n  -e S3_ROOT_USER=admin \\\n  -e S3_ROOT_PASSWORD=changeme123 \\\n  -v /data:/data \\\n  ghcr.io/hanzoai/storage:latest \\\n  server /data --console-address ":9001"'}),(0,s.jsxs)(v,{children:["After starting, access the console at ",(0,s.jsx)("strong",{style:{color:r},children:"http://localhost:9001"})," and the S3 API at ",(0,s.jsx)("strong",{style:{color:r},children:"http://localhost:9000"}),"."]}),(0,s.jsxs)(x,{type:"tip",children:["For production, use a strong password (at least 12 characters) and configure TLS. See the ",(0,s.jsx)("a",{href:"#ops-tls",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"TLS / Network Encryption"})," section."]})]}),(0,s.jsx)(_,{id:"deploy-docker",children:"Deploy with Docker"}),(0,s.jsxs)(v,{children:["Hanzo Space ships as a single container image at ",(0,s.jsx)("code",{style:y,children:"ghcr.io/hanzoai/storage:latest"}),"."]}),(0,s.jsx)(_,{id:"single-node",children:"Single Node, Single Drive"}),(0,s.jsx)(v,{children:"For development, testing, or small workloads:"}),(0,s.jsx)(f,{children:'docker run -d --name hanzo-space \\\n  -p 9000:9000 -p 9001:9001 \\\n  -e S3_ROOT_USER=admin \\\n  -e S3_ROOT_PASSWORD=changeme123 \\\n  -v ~/hanzo-data:/data \\\n  ghcr.io/hanzoai/storage:latest \\\n  server /data --console-address ":9001"'}),(0,s.jsx)(_,{id:"single-node-multi-drive",children:"Single Node, Multi Drive"}),(0,s.jsx)(v,{children:"For production with erasure coding (requires at least 4 drives):"}),(0,s.jsx)(f,{children:'docker run -d --name hanzo-space \\\n  -p 9000:9000 -p 9001:9001 \\\n  -e S3_ROOT_USER=admin \\\n  -e S3_ROOT_PASSWORD=changeme123 \\\n  -v /mnt/disk1:/data1 \\\n  -v /mnt/disk2:/data2 \\\n  -v /mnt/disk3:/data3 \\\n  -v /mnt/disk4:/data4 \\\n  ghcr.io/hanzoai/storage:latest \\\n  server /data{1...4} --console-address ":9001"'}),(0,s.jsxs)(x,{type:"info",children:["Erasure coding provides data redundancy. With 4 drives, you can lose up to 2 drives and still recover all data. See ",(0,s.jsx)("a",{href:"#ops-erasure-coding",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"Erasure Coding"})," for details."]}),(0,s.jsx)(_,{id:"compose",children:"Docker Compose"}),(0,s.jsx)(f,{title:"compose.yml",children:'services:\n  storage:\n    image: ghcr.io/hanzoai/storage:latest\n    command: server /data --console-address ":9001"\n    ports:\n      - "9000:9000"\n      - "9001:9001"\n    environment:\n      S3_ROOT_USER: admin\n      S3_ROOT_PASSWORD: changeme123\n    volumes:\n      - storage-data:/data\n    healthcheck:\n      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n\nvolumes:\n  storage-data:'}),(0,s.jsx)(_,{id:"deploy-binary",children:"Deploy Binary"}),(0,s.jsx)(v,{children:"Download and run directly on Linux, macOS, or Windows:"}),(0,s.jsx)(f,{title:"Linux (amd64)",children:'wget https://github.com/hanzoai/storage/releases/latest/download/s3-linux-amd64\nchmod +x s3-linux-amd64\nsudo mv s3-linux-amd64 /usr/local/bin/s3\n\n# Start server\nS3_ROOT_USER=admin S3_ROOT_PASSWORD=changeme123 \\\n  s3 server /data --console-address ":9001"'}),(0,s.jsx)(f,{title:"macOS",children:'brew install hanzoai/tap/s3\n\n# Start server\nS3_ROOT_USER=admin S3_ROOT_PASSWORD=changeme123 \\\n  s3 server ~/hanzo-data --console-address ":9001"'}),(0,s.jsx)(f,{title:"systemd service",children:'# /etc/systemd/system/hanzo-storage.service\n[Unit]\nDescription=Hanzo Space Object Storage\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nType=notify\nEnvironmentFile=/etc/default/s3\nExecStart=/usr/local/bin/s3 server $S3_VOLUMES --console-address ":9001"\nRestart=always\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target'}),(0,s.jsx)(_,{id:"deploy-kubernetes",children:"Deploy on Kubernetes"}),(0,s.jsx)(v,{children:"Hanzo Space runs on any Kubernetes cluster. Here is a minimal deployment:"}),(0,s.jsx)(f,{title:"storage.yaml",children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: storage\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: storage\n  template:\n    metadata:\n      labels:\n        app: storage\n    spec:\n      containers:\n        - name: storage\n          image: ghcr.io/hanzoai/storage:latest\n          args: ["server", "/data", "--console-address", ":9001"]\n          ports:\n            - containerPort: 9000\n              name: s3\n            - containerPort: 9001\n              name: console\n          env:\n            - name: S3_ROOT_USER\n              valueFrom:\n                secretKeyRef:\n                  name: storage-credentials\n                  key: root-user\n            - name: S3_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: storage-credentials\n                  key: root-password\n          volumeMounts:\n            - name: data\n              mountPath: /data\n          readinessProbe:\n            httpGet:\n              path: /minio/health/ready\n              port: 9000\n            initialDelaySeconds: 10\n            periodSeconds: 10\n          livenessProbe:\n            httpGet:\n              path: /minio/health/live\n              port: 9000\n            initialDelaySeconds: 30\n            periodSeconds: 30\n      volumes:\n        - name: data\n          persistentVolumeClaim:\n            claimName: storage-data\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: storage\nspec:\n  selector:\n    app: storage\n  ports:\n    - port: 9000\n      targetPort: 9000\n      name: s3\n    - port: 9001\n      targetPort: 9001\n      name: console'}),(0,s.jsx)(_,{id:"deploy-distributed",children:"Distributed Deployment"}),(0,s.jsx)(v,{children:"For production high-availability, deploy multiple nodes with erasure coding across all drives. This gives you both data redundancy and horizontal scalability."}),(0,s.jsx)(f,{title:"4-node distributed cluster",children:'# On each of 4 nodes, start with the same command:\nS3_ROOT_USER=admin S3_ROOT_PASSWORD=changeme123 \\\n  s3 server \\\n    http://node{1...4}.storage.example.com/data{1...4} \\\n    --console-address ":9001"\n\n# This creates a 4-node cluster with 16 drives total (4 per node).\n# The cluster can tolerate loss of up to 2 nodes or 8 drives.'}),(0,s.jsx)(x,{type:"warning",children:"All nodes must use the same root credentials and see the same set of endpoints. Start all nodes within a short window \u2014 the cluster requires quorum to initialize."}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Requirements for distributed mode:"})}),(0,s.jsxs)(v,{children:["\u2022 Minimum 4 nodes (or 4 drives on 1 node) for erasure coding",(0,s.jsx)("br",{}),"\u2022 All nodes must have synchronized clocks (use NTP)",(0,s.jsx)("br",{}),"\u2022 All nodes must be reachable on the same port",(0,s.jsx)("br",{}),"\u2022 Use fast, local-attached storage (NVMe/SSD recommended) \u2014 avoid NAS/NFS",(0,s.jsx)("br",{}),"\u2022 All drives should be the same size for optimal space utilization"]}),(0,s.jsx)(_,{id:"first-steps",children:"First Steps"}),(0,s.jsx)(v,{children:"After deploying, here is what to do next:"}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"1. Log in to the console"})," \u2014 Open the console URL (port 9001) in your browser. Sign in with your root credentials or via Hanzo ID SSO."]}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"2. Create a bucket"}),' \u2014 Click "Create Bucket", enter a name, and choose options (versioning, locking, quota).']}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"3. Upload objects"})," \u2014 Drag and drop files into the bucket, or use the S3 API / CLI."]}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"4. Create access keys"})," \u2014 Go to Access Keys \u2192 Create Access Key. These are your S3 credentials for API access."]}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"5. Connect with a client"})," \u2014 Use any S3 SDK or the s3 CLI (see ",(0,s.jsx)("a",{href:"#sdk-cli",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"SDKs"})," section)."]}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"6. Configure TLS"})," \u2014 For production, enable ",(0,s.jsx)("a",{href:"#ops-tls",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"TLS encryption"})," and ",(0,s.jsx)("a",{href:"#auth-oidc",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"OIDC SSO"}),"."]}),(0,s.jsx)(k,{id:"console-overview",children:"Console Guide"}),(0,s.jsx)(v,{children:"The Hanzo Space console is a web-based management interface built into the server. It provides a graphical way to manage buckets, objects, users, policies, and server configuration."}),(0,s.jsxs)(v,{children:["Access the console at ",(0,s.jsx)("strong",{style:{color:r},children:"https://hanzo.space"})," (hosted) or on port 9001 of your self-hosted deployment. Authentication uses Hanzo ID (OIDC SSO) or local access key credentials."]}),(0,s.jsx)(_,{id:"console-buckets",children:"Managing Buckets"}),(0,s.jsx)(v,{children:"The Buckets page shows all buckets in your deployment. From here you can:"}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Create buckets"}),' \u2014 Click "Create Bucket". Options include:']}),(0,s.jsx)(S,{headers:["Option","Description"],rows:[["Versioning","Keep all versions of every object. Required for replication."],["Object Locking","Enable WORM (Write Once Read Many) compliance. Cannot be disabled after creation."],["Quota","Set a maximum size for the bucket."],["Retention","Set default retention period for new objects (governance or compliance mode)."]]}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Delete buckets"})," \u2014 A bucket must be empty before deletion. Use lifecycle rules or ",(0,s.jsx)("code",{style:y,children:"s3 rm --recursive"})," to empty it first."]}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Bucket settings"})," \u2014 Click a bucket, then the Settings tab to configure: versioning, encryption (SSE-S3/SSE-KMS), access policies, replication rules, lifecycle rules, and event notifications."]}),(0,s.jsx)(_,{id:"console-objects",children:"Browsing Objects"}),(0,s.jsx)(v,{children:"Click a bucket to browse its contents. The object browser supports:"}),(0,s.jsxs)(v,{children:["\u2022 ",(0,s.jsx)("strong",{style:{color:r},children:"Upload"}),' \u2014 Drag and drop files or click "Upload" to select files. Supports multi-file and folder upload.',(0,s.jsx)("br",{}),"\u2022 ",(0,s.jsx)("strong",{style:{color:r},children:"Download"}),' \u2014 Click any object to view details, then click "Download".',(0,s.jsx)("br",{}),"\u2022 ",(0,s.jsx)("strong",{style:{color:r},children:"Preview"})," \u2014 Images, PDFs, videos, and text files can be previewed inline.",(0,s.jsx)("br",{}),"\u2022 ",(0,s.jsx)("strong",{style:{color:r},children:"Share"})," \u2014 Generate a presigned URL for temporary public access (configurable expiry, 1 hour to 7 days).",(0,s.jsx)("br",{}),"\u2022 ",(0,s.jsx)("strong",{style:{color:r},children:"Create folders"}),' \u2014 Click "Create Path" to create a folder (prefix) within the bucket.',(0,s.jsx)("br",{}),"\u2022 ",(0,s.jsx)("strong",{style:{color:r},children:"Metadata"})," \u2014 View and edit object metadata, tags, and legal hold status.",(0,s.jsx)("br",{}),"\u2022 ",(0,s.jsx)("strong",{style:{color:r},children:"Versions"}),' \u2014 Toggle "Show Versions" to see all versions. Restore a previous version by copying it as the current version.']}),(0,s.jsx)(_,{id:"console-access",children:"Access Keys"}),(0,s.jsxs)(v,{children:["Access Keys are S3 API credentials. Each key consists of an Access Key (username) and Secret Key (password). Go to ",(0,s.jsx)("strong",{style:{color:r},children:"Access Keys \u2192 Create Access Key"})," to generate a new pair."]}),(0,s.jsx)(v,{children:"You can restrict access keys with an inline policy:"}),(0,s.jsx)(f,{title:"Example: Read-only access to one bucket",children:'{\n  "Version": "2012-10-17",\n  "Statement": [\n    {\n      "Effect": "Allow",\n      "Action": ["s3:GetObject", "s3:ListBucket"],\n      "Resource": [\n        "arn:aws:s3:::my-bucket",\n        "arn:aws:s3:::my-bucket/*"\n      ]\n    }\n  ]\n}'}),(0,s.jsx)(_,{id:"console-monitoring",children:"Monitoring"}),(0,s.jsxs)(v,{children:["The console dashboard shows real-time server metrics: total storage, number of objects, bucket count, uptime, network I/O, and drive health. For production monitoring, see ",(0,s.jsx)("a",{href:"#ops-metrics",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"Metrics & Monitoring"}),"."]}),(0,s.jsx)(k,{id:"s3-compatibility",children:"S3 API Compatibility"}),(0,s.jsxs)(v,{children:["Hanzo Space implements the Amazon S3 API. All S3 SDKs, CLIs, and tools work without modification. The S3 API endpoint is on port 9000 (default) or at ",(0,s.jsx)("strong",{style:{color:r},children:"https://s3.hanzo.ai"})," for the hosted service."]}),(0,s.jsx)(_,{id:"s3-buckets",children:"Bucket Operations"}),(0,s.jsx)(S,{headers:["Operation","S3 API","Description"],rows:[["Create Bucket","PUT /bucket","Create a new bucket"],["List Buckets","GET /","List all buckets"],["Delete Bucket","DELETE /bucket","Delete an empty bucket"],["Head Bucket","HEAD /bucket","Check if a bucket exists"],["Get Bucket Location","GET /bucket?location","Get the bucket region"],["Get Bucket Versioning","GET /bucket?versioning","Get versioning status"],["Put Bucket Versioning","PUT /bucket?versioning","Enable/suspend versioning"],["Get Bucket Policy","GET /bucket?policy","Get the bucket policy JSON"],["Put Bucket Policy","PUT /bucket?policy","Set the bucket policy"],["Get Bucket Encryption","GET /bucket?encryption","Get default encryption config"],["Put Bucket Encryption","PUT /bucket?encryption","Set default encryption (SSE-S3/SSE-KMS)"],["Get Bucket Tagging","GET /bucket?tagging","Get bucket tags"],["Put Bucket Tagging","PUT /bucket?tagging","Set bucket tags"],["List Objects v2","GET /bucket?list-type=2","List objects with pagination"],["Get Bucket Notification","GET /bucket?notification","Get event notification config"],["Put Bucket Notification","PUT /bucket?notification","Set event notification rules"]]}),(0,s.jsx)(_,{id:"s3-objects",children:"Object Operations"}),(0,s.jsx)(S,{headers:["Operation","S3 API","Description"],rows:[["Put Object","PUT /bucket/key","Upload an object (up to 5 TB)"],["Get Object","GET /bucket/key","Download an object"],["Head Object","HEAD /bucket/key","Get object metadata"],["Delete Object","DELETE /bucket/key","Delete an object"],["Delete Objects","POST /bucket?delete","Bulk delete up to 1000 objects"],["Copy Object","PUT /bucket/key (x-amz-copy-source)","Copy an object"],["List Object Versions","GET /bucket?versions","List all versions of objects"],["Put Object Tags","PUT /bucket/key?tagging","Set object tags"],["Get Object Tags","GET /bucket/key?tagging","Get object tags"],["Put Object Retention","PUT /bucket/key?retention","Set object retention (WORM)"],["Put Object Legal Hold","PUT /bucket/key?legal-hold","Set/remove legal hold"],["Select Object Content","POST /bucket/key?select","Query CSV/JSON/Parquet with SQL"],["Restore Object","POST /bucket/key?restore","Restore from tier/archive"]]}),(0,s.jsx)(_,{id:"s3-presigned",children:"Presigned URLs"}),(0,s.jsx)(v,{children:"Generate temporary URLs that allow unauthenticated access to private objects. Supported by all SDKs:"}),(0,s.jsx)(f,{title:"JavaScript",children:"import { S3Client } from 'hanzo-s3'\n\nconst client = new S3Client({\n  endPoint: 's3.hanzo.ai',\n  useSSL: true,\n  accessKey: 'YOUR_ACCESS_KEY',\n  secretKey: 'YOUR_SECRET_KEY',\n})\n\n// Generate a download URL valid for 1 hour\nconst url = await client.presignedGetObject('my-bucket', 'photo.jpg', 3600)\n\n// Generate an upload URL valid for 1 hour\nconst uploadUrl = await client.presignedPutObject('my-bucket', 'upload.txt', 3600)"}),(0,s.jsx)(f,{title:"Python",children:'from hanzo_s3 import S3Client\nfrom datetime import timedelta\n\nclient = S3Client("s3.hanzo.ai", access_key="YOUR_ACCESS_KEY",\n               secret_key="YOUR_SECRET_KEY", secure=True)\n\nurl = client.presigned_get_object("my-bucket", "photo.jpg", expires=timedelta(hours=1))\nprint(url)'}),(0,s.jsx)(_,{id:"s3-multipart",children:"Multipart Upload"}),(0,s.jsxs)(v,{children:["For objects larger than 5 MB, use multipart upload. The SDKs handle this automatically \u2014 any ",(0,s.jsx)("code",{style:y,children:"putObject"})," call with a large file will automatically split into parts, upload in parallel, and reassemble on the server."]}),(0,s.jsx)(S,{headers:["Limit","Value"],rows:[["Minimum part size","5 MB"],["Maximum part size","5 GB"],["Maximum parts per upload","10,000"],["Maximum object size","5 TB"]]}),(0,s.jsx)(f,{title:"Manual multipart (s3)",children:"# Upload a 10 GB file \u2014 s3 handles multipart automatically\ns3 cp large-file.zip hanzo/backups/\n\n# Monitor in-progress uploads\ns3 ls --incomplete hanzo/backups/\n\n# Abort stale multipart uploads older than 7 days\ns3 rm --incomplete --older-than 7d hanzo/backups/"}),(0,s.jsx)(k,{id:"sdk-javascript",children:"JavaScript SDK"}),(0,s.jsx)(f,{title:"Install",children:"npm install hanzo-s3"}),(0,s.jsx)(f,{title:"Usage",children:"import { S3Client } from 'hanzo-s3'\n\nconst client = new S3Client({\n  endPoint: 's3.hanzo.ai',\n  port: 443,\n  useSSL: true,\n  accessKey: 'YOUR_ACCESS_KEY',\n  secretKey: 'YOUR_SECRET_KEY',\n})\n\n// List buckets\nconst buckets = await client.listBuckets()\nconsole.log(buckets)\n\n// Upload a file\nawait client.fPutObject('my-bucket', 'hello.txt', '/path/to/hello.txt')\n\n// Download a file\nawait client.fGetObject('my-bucket', 'hello.txt', '/tmp/hello.txt')\n\n// Stream upload\nawait client.putObject('my-bucket', 'data.json', Buffer.from('{\"key\":\"value\"}'))\n\n// List objects\nconst stream = client.listObjects('my-bucket', '', true)\nstream.on('data', (obj) => console.log(obj))\nstream.on('end', () => console.log('done'))\n\n// Delete an object\nawait client.removeObject('my-bucket', 'hello.txt')"}),(0,s.jsx)(k,{id:"sdk-python",children:"Python SDK"}),(0,s.jsx)(f,{title:"Install",children:"pip install hanzo-s3"}),(0,s.jsx)(f,{title:"Usage",children:'from hanzo_s3 import S3Client\nfrom hanzo_s3.error import S3Error\n\nclient = S3Client(\n    "s3.hanzo.ai",\n    access_key="YOUR_ACCESS_KEY",\n    secret_key="YOUR_SECRET_KEY",\n    secure=True,\n)\n\n# List buckets\nfor bucket in client.list_buckets():\n    print(bucket.name, bucket.creation_date)\n\n# Create a bucket\nif not client.bucket_exists("my-bucket"):\n    client.make_bucket("my-bucket")\n\n# Upload a file\nclient.fput_object("my-bucket", "hello.txt", "/path/to/hello.txt")\n\n# Upload bytes\nfrom io import BytesIO\ndata = BytesIO(b"Hello, Hanzo Space!")\nclient.put_object("my-bucket", "greeting.txt", data, len(data.getvalue()))\n\n# Download a file\nclient.fget_object("my-bucket", "hello.txt", "/tmp/hello.txt")\n\n# List objects\nfor obj in client.list_objects("my-bucket", recursive=True):\n    print(obj.object_name, obj.size)\n\n# Delete an object\nclient.remove_object("my-bucket", "hello.txt")'}),(0,s.jsx)(k,{id:"sdk-go",children:"Go SDK"}),(0,s.jsx)(f,{title:"Install",children:"go get github.com/hanzoai/s3-go/v7"}),(0,s.jsx)(f,{title:"Usage",children:'package main\n\nimport (\n    "context"\n    "fmt"\n    "log"\n    "os"\n\n    "github.com/hanzoai/s3-go/v7"\n    "github.com/hanzoai/s3-go/v7/pkg/credentials"\n)\n\nfunc main() {\n    client, err := s3.New("s3.hanzo.ai", &s3.Options{\n        Creds:  credentials.NewStaticV4("YOUR_ACCESS_KEY", "YOUR_SECRET_KEY", ""),\n        Secure: true,\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    ctx := context.Background()\n\n    // List buckets\n    buckets, _ := client.ListBuckets(ctx)\n    for _, bucket := range buckets {\n        fmt.Println(bucket.Name)\n    }\n\n    // Upload a file\n    _, err = client.FPutObject(ctx, "my-bucket", "hello.txt", "/path/to/hello.txt",\n        s3.PutObjectOptions{ContentType: "text/plain"})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Download a file\n    err = client.FGetObject(ctx, "my-bucket", "hello.txt", "/tmp/hello.txt",\n        s3.GetObjectOptions{})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Stream upload\n    file, _ := os.Open("/path/to/large-file.zip")\n    defer file.Close()\n    stat, _ := file.Stat()\n    _, err = client.PutObject(ctx, "my-bucket", "large-file.zip", file, stat.Size(),\n        s3.PutObjectOptions{ContentType: "application/zip"})\n}'}),(0,s.jsx)(k,{id:"sdk-java",children:"Java SDK"}),(0,s.jsx)(f,{title:"Maven dependency",children:"<dependency>\n    <groupId>ai.hanzo.s3</groupId>\n    <artifactId>hanzo-s3</artifactId>\n    <version>8.5.7</version>\n</dependency>"}),(0,s.jsx)(f,{title:"Usage",children:'import ai.hanzo.s3.*;\n\npublic class StorageExample {\n    public static void main(String[] args) throws Exception {\n        HanzoS3Client client = HanzoS3Client.builder()\n            .endpoint("https://s3.hanzo.ai")\n            .credentials("YOUR_ACCESS_KEY", "YOUR_SECRET_KEY")\n            .build();\n\n        // Create a bucket\n        if (!client.bucketExists(BucketExistsArgs.builder().bucket("my-bucket").build())) {\n            client.makeBucket(MakeBucketArgs.builder().bucket("my-bucket").build());\n        }\n\n        // Upload a file\n        client.uploadObject(UploadObjectArgs.builder()\n            .bucket("my-bucket")\n            .object("hello.txt")\n            .filename("/path/to/hello.txt")\n            .build());\n\n        // Download a file\n        client.downloadObject(DownloadObjectArgs.builder()\n            .bucket("my-bucket")\n            .object("hello.txt")\n            .filename("/tmp/hello.txt")\n            .build());\n    }\n}'}),(0,s.jsx)(k,{id:"sdk-cli",children:"s3 CLI"}),(0,s.jsxs)(v,{children:[(0,s.jsx)("code",{style:y,children:"s3"})," is the official command-line client for S3-compatible storage. It provides Unix-like commands (ls, cp, rm, cat, diff, mirror) for object storage."]}),(0,s.jsx)(f,{title:"Install",children:'# macOS\nbrew install hanzoai/tap/s3\n\n# Linux\ncurl -O https://github.com/hanzoai/storage/releases/latest/download/s3-linux-amd64\nchmod +x s3-linux-amd64 && sudo mv s3-linux-amd64 /usr/local/bin/s3\n\n# Windows (PowerShell)\nInvoke-WebRequest -Uri "https://github.com/hanzoai/storage/releases/latest/download/s3-windows-amd64.exe" -OutFile "s3.exe"'}),(0,s.jsx)(f,{title:"Configure",children:"# Add your Hanzo Space server\ns3 alias set hanzo https://s3.hanzo.ai YOUR_ACCESS_KEY YOUR_SECRET_KEY"}),(0,s.jsx)(f,{title:"Common commands",children:'# List buckets\ns3 ls hanzo\n\n# Create a bucket\ns3 mb hanzo/my-bucket\n\n# Upload a file\ns3 cp file.txt hanzo/my-bucket/\n\n# Upload a directory recursively\ns3 cp --recursive ./data/ hanzo/my-bucket/data/\n\n# Download a file\ns3 cp hanzo/my-bucket/file.txt ./\n\n# List objects\ns3 ls hanzo/my-bucket/\n\n# Remove an object\ns3 rm hanzo/my-bucket/file.txt\n\n# Mirror a directory (sync)\ns3 mirror ./local-dir/ hanzo/my-bucket/\n\n# View object contents\ns3 cat hanzo/my-bucket/config.json\n\n# Get bucket/object info\ns3 stat hanzo/my-bucket\ns3 stat hanzo/my-bucket/file.txt\n\n# Set bucket policy to public read\ns3 anonymous set download hanzo/my-bucket\n\n# Find objects matching a pattern\ns3 find hanzo/my-bucket --name "*.log" --older 30d\n\n# Calculate disk usage\ns3 du hanzo/my-bucket'}),(0,s.jsx)(k,{id:"sdk-cli-admin",children:"s3 Admin Commands"}),(0,s.jsx)(v,{children:"Administrative commands for server management:"}),(0,s.jsx)(f,{children:"# Server info\ns3 admin info hanzo\n\n# View server configuration\ns3 admin config get hanzo\n\n# Set a configuration key\ns3 admin config set hanzo compression enable=on\n\n# Restart server (applies config changes)\ns3 admin service restart hanzo\n\n# View real-time server logs\ns3 admin trace hanzo\n\n# View audit logs\ns3 admin trace hanzo --call s3\n\n# User management\ns3 admin user add hanzo newuser newpassword\ns3 admin user list hanzo\ns3 admin user remove hanzo newuser\n\n# Group management\ns3 admin group add hanzo developers user1 user2\ns3 admin group list hanzo\n\n# Policy management\ns3 admin policy create hanzo my-policy policy.json\ns3 admin policy attach hanzo my-policy --user=newuser\n\n# Healing (data repair)\ns3 admin heal hanzo --recursive\n\n# Prometheus metrics\ns3 admin prometheus generate hanzo"}),(0,s.jsx)(k,{id:"sdk-aws",children:"AWS CLI"}),(0,s.jsx)(v,{children:"Hanzo Space is fully compatible with the AWS CLI. Configure it to point to your Hanzo Space endpoint:"}),(0,s.jsx)(f,{title:"Configure",children:"aws configure\n# AWS Access Key ID: YOUR_ACCESS_KEY\n# AWS Secret Access Key: YOUR_SECRET_KEY\n# Default region name: us-east-1\n# Default output format: json\n\n# Set endpoint\naws configure set default.s3.endpoint_url https://s3.hanzo.ai\naws configure set default.s3api.endpoint_url https://s3.hanzo.ai"}),(0,s.jsx)(f,{title:"Usage",children:"# List buckets\naws s3 ls\n\n# Create a bucket\naws s3 mb s3://my-bucket\n\n# Upload\naws s3 cp file.txt s3://my-bucket/\n\n# Download\naws s3 cp s3://my-bucket/file.txt ./\n\n# Sync a directory\naws s3 sync ./local/ s3://my-bucket/remote/\n\n# List objects\naws s3 ls s3://my-bucket/ --recursive\n\n# Presigned URL\naws s3 presign s3://my-bucket/file.txt --expires-in 3600"}),(0,s.jsx)(k,{id:"auth-oidc",children:"OIDC / SSO Authentication"}),(0,s.jsxs)(v,{children:["Hanzo Space supports OpenID Connect (OIDC) for single sign-on. On ",(0,s.jsx)("strong",{style:{color:r},children:"hanzo.space"}),', this is pre-configured with Hanzo ID \u2014 click "Sign In" and you are redirected to hanzo.id for authentication.']}),(0,s.jsx)(v,{children:"For self-hosted deployments, configure OIDC with these environment variables:"}),(0,s.jsx)(S,{headers:["Variable","Description"],rows:[["S3_IDENTITY_OPENID_CONFIG_URL","OIDC discovery URL, e.g. https://hanzo.id/.well-known/openid-configuration"],["S3_IDENTITY_OPENID_CLIENT_ID","OAuth2 client ID"],["S3_IDENTITY_OPENID_CLIENT_SECRET","OAuth2 client secret"],["S3_IDENTITY_OPENID_CLAIM_NAME","JWT claim for policy mapping (default: policy)"],["S3_IDENTITY_OPENID_SCOPES","Scopes to request (default: openid,profile,email)"],["S3_IDENTITY_OPENID_REDIRECT_URI","Callback URL for the console"],["S3_IDENTITY_OPENID_DISPLAY_NAME","Display name on login page (e.g. Hanzo)"],["S3_IDENTITY_OPENID_CLAIM_USERINFO","Set to on to fetch claims from userinfo endpoint"],["S3_IDENTITY_OPENID_ROLE_POLICY","Default policy for all OIDC users (e.g. readwrite)"]]}),(0,s.jsx)(f,{title:"Example: Hanzo ID OIDC",children:"S3_IDENTITY_OPENID_CONFIG_URL=https://hanzo.id/.well-known/openid-configuration\nS3_IDENTITY_OPENID_CLIENT_ID=hanzo-storage-client-id\nS3_IDENTITY_OPENID_CLIENT_SECRET=hanzo-storage-client-secret\nS3_IDENTITY_OPENID_SCOPES=openid,profile,email\nS3_IDENTITY_OPENID_REDIRECT_URI=https://hanzo.space/oauth_callback\nS3_IDENTITY_OPENID_DISPLAY_NAME=Hanzo\nS3_IDENTITY_OPENID_CLAIM_NAME=policy\nS3_IDENTITY_OPENID_ROLE_POLICY=consoleAdmin"}),(0,s.jsxs)(x,{type:"info",children:["Multiple OIDC providers are supported. Use a suffix: ",(0,s.jsx)("code",{style:y,children:"S3_IDENTITY_OPENID_CONFIG_URL_PROVIDER2=..."})]}),(0,s.jsx)(_,{id:"auth-ldap",children:"LDAP / Active Directory"}),(0,s.jsx)(v,{children:"Hanzo Space supports LDAP and Active Directory for enterprise identity management:"}),(0,s.jsx)(S,{headers:["Variable","Description"],rows:[["S3_IDENTITY_LDAP_SERVER_ADDR","LDAP server address (e.g. ldap.example.com:636)"],["S3_IDENTITY_LDAP_LOOKUP_BIND_DN","Bind DN for lookups (e.g. cn=admin,dc=example,dc=com)"],["S3_IDENTITY_LDAP_LOOKUP_BIND_PASSWORD","Password for the lookup bind DN"],["S3_IDENTITY_LDAP_USER_DN_SEARCH_BASE_DN","Base DN for user searches (e.g. dc=example,dc=com)"],["S3_IDENTITY_LDAP_USER_DN_SEARCH_FILTER","LDAP filter for users (e.g. (uid=%s))"],["S3_IDENTITY_LDAP_GROUP_SEARCH_BASE_DN","Base DN for group searches"],["S3_IDENTITY_LDAP_GROUP_SEARCH_FILTER","Filter for group membership (e.g. (&(objectclass=groupOfNames)(member=%d)))"],["S3_IDENTITY_LDAP_TLS_SKIP_VERIFY","Skip TLS certificate verification (not for production)"]]}),(0,s.jsx)(f,{title:"Example: Active Directory",children:'S3_IDENTITY_LDAP_SERVER_ADDR=ldaps://ad.example.com:636\nS3_IDENTITY_LDAP_LOOKUP_BIND_DN="cn=svc-storage,ou=ServiceAccounts,dc=example,dc=com"\nS3_IDENTITY_LDAP_LOOKUP_BIND_PASSWORD=service-account-password\nS3_IDENTITY_LDAP_USER_DN_SEARCH_BASE_DN="dc=example,dc=com"\nS3_IDENTITY_LDAP_USER_DN_SEARCH_FILTER="(&(objectCategory=person)(sAMAccountName=%s))"\nS3_IDENTITY_LDAP_GROUP_SEARCH_BASE_DN="ou=Groups,dc=example,dc=com"\nS3_IDENTITY_LDAP_GROUP_SEARCH_FILTER="(&(objectclass=group)(member=%d))"'}),(0,s.jsx)(v,{children:"After configuring LDAP, map LDAP groups to policies:"}),(0,s.jsx)(f,{children:'s3 admin policy attach hanzo readwrite --group="cn=developers,ou=Groups,dc=example,dc=com"\ns3 admin policy attach hanzo consoleAdmin --group="cn=admins,ou=Groups,dc=example,dc=com"'}),(0,s.jsx)(_,{id:"auth-iam",children:"IAM Policies"}),(0,s.jsx)(v,{children:"Hanzo Space uses AWS IAM-compatible policies for access control. Policies are JSON documents that define allowed or denied actions on specific resources."}),(0,s.jsx)(v,{children:"Built-in policies:"}),(0,s.jsx)(S,{headers:["Policy","Description"],rows:[["readonly","Read-only access to all buckets and objects"],["readwrite","Full read/write access to all buckets and objects"],["writeonly","Write-only access (upload only, no list or download)"],["diagnostics","Access to server health and metrics endpoints"],["consoleAdmin","Full admin access including user/policy management"]]}),(0,s.jsx)(f,{title:"Custom policy example",children:'{\n  "Version": "2012-10-17",\n  "Statement": [\n    {\n      "Effect": "Allow",\n      "Action": [\n        "s3:GetObject",\n        "s3:PutObject",\n        "s3:DeleteObject",\n        "s3:ListBucket"\n      ],\n      "Resource": [\n        "arn:aws:s3:::uploads",\n        "arn:aws:s3:::uploads/*"\n      ]\n    },\n    {\n      "Effect": "Deny",\n      "Action": ["s3:DeleteBucket"],\n      "Resource": ["arn:aws:s3:::*"]\n    }\n  ]\n}'}),(0,s.jsx)(f,{title:"Apply a custom policy",children:"# Create policy\ns3 admin policy create hanzo upload-only upload-policy.json\n\n# Attach to user\ns3 admin policy attach hanzo upload-only --user=uploader\n\n# Attach to group\ns3 admin policy attach hanzo upload-only --group=uploaders"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Supported IAM policy actions:"})}),(0,s.jsx)(S,{headers:["Action","Description"],rows:[["s3:GetObject","Download objects"],["s3:PutObject","Upload objects"],["s3:DeleteObject","Delete objects"],["s3:ListBucket","List objects in a bucket"],["s3:ListAllMyBuckets","List all buckets"],["s3:CreateBucket","Create new buckets"],["s3:DeleteBucket","Delete buckets"],["s3:GetBucketLocation","Get bucket region"],["s3:GetBucketPolicy","Read bucket policies"],["s3:PutBucketPolicy","Write bucket policies"],["s3:GetBucketNotification","Read notification config"],["s3:PutBucketNotification","Write notification config"],["s3:ListMultipartUploadParts","List multipart upload parts"],["s3:AbortMultipartUpload","Abort in-progress multipart uploads"]]}),(0,s.jsx)(_,{id:"auth-encryption",children:"Encryption"}),(0,s.jsx)(v,{children:"Hanzo Space supports server-side encryption (SSE) with three modes:"}),(0,s.jsx)(S,{headers:["Mode","Description"],rows:[["SSE-S3","Server manages encryption keys. Enable per-bucket via the console or API."],["SSE-KMS","Use an external KMS (e.g., HashiCorp Vault, AWS KMS) for key management."],["SSE-C","Client provides the encryption key with each request."]]}),(0,s.jsx)(f,{title:"Enable SSE-S3 on a bucket",children:"s3 encrypt set sse-s3 hanzo/my-bucket"}),(0,s.jsx)(f,{title:"Enable SSE-KMS",children:"# Configure KMS\nS3_KMS_KES_ENDPOINT=https://kes.example.com:7373\nS3_KMS_KES_KEY_FILE=/path/to/client.key\nS3_KMS_KES_CERT_FILE=/path/to/client.crt\nS3_KMS_KES_CAPATH=/path/to/ca.crt\nS3_KMS_KES_KEY_NAME=my-encryption-key\n\n# Enable SSE-KMS on a bucket\ns3 encrypt set sse-kms my-encryption-key hanzo/secure-bucket"}),(0,s.jsxs)(v,{children:["For TLS configuration, see ",(0,s.jsx)("a",{href:"#ops-tls",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"TLS / Network Encryption"}),"."]}),(0,s.jsx)(_,{id:"auth-bucket-policy",children:"Bucket Policies"}),(0,s.jsx)(v,{children:"Bucket policies control anonymous and cross-account access. Common use cases:"}),(0,s.jsx)(f,{title:"Public read-only bucket",children:'{\n  "Version": "2012-10-17",\n  "Statement": [\n    {\n      "Effect": "Allow",\n      "Principal": "*",\n      "Action": ["s3:GetObject"],\n      "Resource": ["arn:aws:s3:::public-assets/*"]\n    }\n  ]\n}'}),(0,s.jsx)(f,{title:"IP-restricted access",children:'{\n  "Version": "2012-10-17",\n  "Statement": [\n    {\n      "Effect": "Allow",\n      "Principal": "*",\n      "Action": ["s3:GetObject", "s3:PutObject"],\n      "Resource": ["arn:aws:s3:::internal-data/*"],\n      "Condition": {\n        "IpAddress": {\n          "aws:SourceIp": ["10.0.0.0/8", "172.16.0.0/12"]\n        }\n      }\n    }\n  ]\n}'}),(0,s.jsx)(f,{title:"Set via s3 CLI",children:"# Public download access\ns3 anonymous set download hanzo/public-assets\n\n# Upload-only (drop box)\ns3 anonymous set upload hanzo/uploads\n\n# Apply custom JSON policy\ns3 anonymous set-json policy.json hanzo/my-bucket"}),(0,s.jsx)(k,{id:"admin-config",children:"Server Configuration"}),(0,s.jsx)(v,{children:"Hanzo Space is configured via environment variables. Key settings:"}),(0,s.jsx)(S,{headers:["Variable","Default","Description"],rows:[["S3_ROOT_USER","(required)","Root username (minimum 3 characters)"],["S3_ROOT_PASSWORD","(required)","Root password (minimum 8 characters)"],["S3_VOLUMES","/data","Data directory or drive paths"],["S3_SERVER_URL","","Public URL for the S3 API (for presigned URLs)"],["S3_BROWSER_REDIRECT_URL","","Public URL for the console"],["S3_REGION","us-east-1","Server region (used in S3 responses)"],["S3_DOMAIN","","Virtual-hosted-style domain (e.g., s3.example.com)"],["S3_COMPRESSION_ENABLE","off","Enable transparent compression"],["S3_COMPRESSION_EXTENSIONS",".txt,.log,.csv,.json,.xml","File extensions to compress"],["S3_COMPRESSION_MIME_TYPES","text/*,application/json,application/xml","MIME types to compress"],["S3_PROMETHEUS_AUTH_TYPE","jwt","Prometheus metrics auth (jwt or public)"],["S3_PROMETHEUS_URL","","Prometheus server URL for console dashboards"],["S3_SCANNER_SPEED","default","Background scanner speed (fastest/fast/default/slow/slowest)"],["S3_API_REQUESTS_MAX","0","Maximum concurrent API requests (0 = unlimited)"],["S3_API_REQUESTS_DEADLINE","10s","Deadline for queued API requests"],["S3_HEAL_BITROTSCAN","on","Enable bitrot scanning during healing"]]}),(0,s.jsx)(f,{title:"Config file (/etc/default/s3)",children:'# Root credentials\nS3_ROOT_USER=admin\nS3_ROOT_PASSWORD=a-strong-password-here\n\n# Volumes (4 drives for erasure coding)\nS3_VOLUMES="/data{1...4}"\n\n# Public URLs\nS3_SERVER_URL=https://s3.example.com\nS3_BROWSER_REDIRECT_URL=https://console.example.com\n\n# Region\nS3_REGION=us-east-1\n\n# Enable compression\nS3_COMPRESSION_ENABLE=on\n\n# OIDC\nS3_IDENTITY_OPENID_CONFIG_URL=https://hanzo.id/.well-known/openid-configuration\nS3_IDENTITY_OPENID_CLIENT_ID=my-client-id\nS3_IDENTITY_OPENID_DISPLAY_NAME=Hanzo'}),(0,s.jsx)(v,{children:"Runtime configuration changes via s3 CLI:"}),(0,s.jsx)(f,{children:"# View all configuration\ns3 admin config get hanzo\n\n# Enable compression\ns3 admin config set hanzo compression enable=on\n\n# Configure scanner speed\ns3 admin config set hanzo scanner speed=fast\n\n# Set API rate limits\ns3 admin config set hanzo api requests_max=500\n\n# Apply changes (requires restart)\ns3 admin service restart hanzo"}),(0,s.jsx)(_,{id:"admin-lifecycle",children:"Lifecycle Rules"}),(0,s.jsx)(v,{children:"Lifecycle rules automate object transitions and expiration:"}),(0,s.jsx)(f,{title:"Expire objects after 90 days",children:"s3 ilm rule add hanzo/logs --expiry-days 90"}),(0,s.jsx)(f,{title:"Expire noncurrent versions after 30 days",children:"s3 ilm rule add hanzo/data --noncurrent-expire-days 30"}),(0,s.jsx)(f,{title:"Expire delete markers",children:"s3 ilm rule add hanzo/data --expire-delete-marker"}),(0,s.jsx)(f,{title:"Abort incomplete multipart uploads",children:"s3 ilm rule add hanzo/uploads --expire-all-object-size-less-than 1MB"}),(0,s.jsx)(f,{title:"List lifecycle rules",children:"s3 ilm rule list hanzo/my-bucket"}),(0,s.jsxs)(v,{children:["Lifecycle rules can also transition objects to a remote tier. See ",(0,s.jsx)("a",{href:"#admin-tiering",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"Tiering"}),"."]}),(0,s.jsx)(_,{id:"admin-tiering",children:"Tiering & Transitions"}),(0,s.jsx)(v,{children:"Tier objects to cheaper storage (AWS S3, GCS, Azure Blob, or another Hanzo Space instance) after a specified number of days:"}),(0,s.jsx)(f,{title:"Add a remote tier",children:"# Add AWS S3 tier\ns3 ilm tier add s3 hanzo WARM-S3 \\\n  --endpoint https://s3.amazonaws.com \\\n  --access-key AWS_ACCESS_KEY \\\n  --secret-key AWS_SECRET_KEY \\\n  --bucket my-archive-bucket \\\n  --region us-east-1\n\n# Add Google Cloud Storage tier\ns3 ilm tier add gcs hanzo COLD-GCS \\\n  --credentials-file /path/to/gcs-credentials.json \\\n  --bucket my-gcs-archive\n\n# Add Azure Blob tier\ns3 ilm tier add azure hanzo ARCHIVE-AZURE \\\n  --account-name myaccount \\\n  --account-key mykey \\\n  --bucket my-container\n\n# Add remote Hanzo Space tier\ns3 ilm tier add s3 hanzo REMOTE-STORAGE \\\n  --endpoint https://remote.example.com \\\n  --access-key REMOTE_KEY \\\n  --secret-key REMOTE_SECRET \\\n  --bucket remote-archive"}),(0,s.jsx)(f,{title:"Create a transition rule",children:"# Transition to WARM-S3 after 30 days\ns3 ilm rule add hanzo/my-bucket --transition-days 30 --storage-class WARM-S3\n\n# Transition noncurrent versions after 7 days\ns3 ilm rule add hanzo/my-bucket --noncurrent-transition-days 7 --noncurrent-storage-class COLD-GCS"}),(0,s.jsx)(x,{type:"info",children:"Tiered objects appear in the bucket listing but their data is stored on the remote tier. Accessing a tiered object transparently retrieves it from the remote storage."}),(0,s.jsx)(_,{id:"admin-replication",children:"Replication"}),(0,s.jsx)(v,{children:"Hanzo Space supports bucket-level and site-level replication for disaster recovery and geographic distribution:"}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Bucket Replication"})," \u2014 Replicate objects between buckets on different servers. Requires versioning on both buckets."]}),(0,s.jsx)(f,{children:"# Enable versioning on both source and target\ns3 version enable source/my-bucket\ns3 version enable target/my-bucket\n\n# Add replication target\ns3 replicate add source/my-bucket \\\n  --remote-bucket my-bucket \\\n  --remote-target https://ACCESS_KEY:SECRET_KEY@remote.example.com\n\n# Check replication status\ns3 replicate status source/my-bucket\n\n# View replication metrics\ns3 replicate backlog source/my-bucket"}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Site Replication"})," \u2014 Synchronize everything (buckets, objects, policies, IAM) across multiple sites for active-active HA."]}),(0,s.jsx)(f,{children:"# Set up site replication between two clusters\ns3 admin replicate add site1 site2\n\n# Check replication status\ns3 admin replicate info site1\n\n# Remove site replication\ns3 admin replicate remove site1"}),(0,s.jsx)(_,{id:"admin-notifications",children:"Event Notifications"}),(0,s.jsx)(v,{children:"Hanzo Space can publish bucket events (object created, deleted, accessed) to external services:"}),(0,s.jsx)(S,{headers:["Target","Config Key","Use Case"],rows:[["Webhook","notify_webhook","HTTP POST to any URL"],["Kafka","notify_kafka","Stream events to Kafka topics"],["AMQP (RabbitMQ)","notify_amqp","Publish to message queues"],["Redis","notify_redis","Push to Redis pub/sub channels"],["PostgreSQL","notify_postgres","Insert events into a database table"],["MySQL","notify_mysql","Insert events into MySQL"],["Elasticsearch","notify_elasticsearch","Index events for search"],["NATS","notify_nats","Cloud-native messaging"],["NSQ","notify_nsq","Real-time distributed messaging"]]}),(0,s.jsx)(f,{title:"Configure webhook notifications",children:'s3 admin config set hanzo notify_webhook:primary \\\n  endpoint="https://api.example.com/hooks/storage" \\\n  queue_limit="10000"\n\n# Restart to apply\ns3 admin service restart hanzo\n\n# Subscribe bucket to events\ns3 event add hanzo/my-bucket arn:minio:sqs::primary:webhook \\\n  --event put,delete\n\n# List configured events\ns3 event list hanzo/my-bucket\n\n# Remove event subscription\ns3 event remove hanzo/my-bucket arn:minio:sqs::primary:webhook'}),(0,s.jsx)(f,{title:"Configure Kafka notifications",children:'s3 admin config set hanzo notify_kafka:primary \\\n  brokers="kafka1:9092,kafka2:9092" \\\n  topic="storage-events" \\\n  queue_limit="10000"\n\ns3 admin service restart hanzo\ns3 event add hanzo/my-bucket arn:minio:sqs::primary:kafka --event put'}),(0,s.jsx)(_,{id:"admin-versioning",children:"Versioning"}),(0,s.jsx)(v,{children:"Bucket versioning keeps all versions of an object, allowing you to recover from accidental deletes or overwrites."}),(0,s.jsx)(f,{children:"# Enable versioning on a bucket\ns3 version enable hanzo/my-bucket\n\n# Check versioning status\ns3 version info hanzo/my-bucket\n\n# List object versions\ns3 ls --versions hanzo/my-bucket/file.txt\n\n# Restore a previous version\ns3 cp --version-id VERSION_ID hanzo/my-bucket/file.txt hanzo/my-bucket/file.txt\n\n# Permanently delete a specific version\ns3 rm --version-id VERSION_ID hanzo/my-bucket/file.txt\n\n# Suspend versioning (existing versions are preserved)\ns3 version suspend hanzo/my-bucket"}),(0,s.jsxs)(x,{type:"info",children:["Versioning is required for bucket replication and object locking. Once enabled, it can be suspended but not fully disabled. Use ",(0,s.jsx)("a",{href:"#admin-lifecycle",style:{color:d,transition:"opacity 0.15s",cursor:"pointer"},children:"lifecycle rules"})," to expire old versions automatically."]}),(0,s.jsx)(k,{id:"ops-erasure-coding",children:"Erasure Coding"}),(0,s.jsx)(v,{children:"Erasure coding is the data protection mechanism used in distributed Hanzo Space deployments. It splits each object into data and parity shards distributed across drives, providing redundancy without full replication."}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"How it works:"})}),(0,s.jsxs)(v,{children:["When you write an object, it is split into ",(0,s.jsx)("em",{children:"data shards"})," and ",(0,s.jsx)("em",{children:"parity shards"}),". The parity shards allow the system to reconstruct the original data even if some drives fail. The default parity is EC:4 for 16 drives (can tolerate loss of 4 drives)."]}),(0,s.jsx)(S,{headers:["Drives","Data Shards","Parity Shards","Drives Tolerated"],rows:[["4","2","2","2"],["8","4","4","4"],["16","12","4","4"],["32","28","4","4"]]}),(0,s.jsx)(f,{title:"Configure erasure coding parity",children:"# Set standard parity (for normal objects)\ns3 admin config set hanzo storage_class standard=EC:4\n\n# Set reduced redundancy (for less critical data)\ns3 admin config set hanzo storage_class rrs=EC:2\n\ns3 admin service restart hanzo"}),(0,s.jsx)(x,{type:"warning",children:"Erasure coding requires a minimum of 4 drives. Single-drive deployments have no data redundancy \u2014 use RAID or replicate to another server for protection."}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Storage overhead:"})," With EC:4 on 16 drives, the overhead is 4/16 = 25%. This is much less than the 100% overhead of simple replication. The tradeoff is that CPU is used for encoding/decoding."]}),(0,s.jsx)(_,{id:"ops-healing",children:"Healing"}),(0,s.jsx)(v,{children:"Healing is the process of repairing corrupted or missing data shards. Hanzo Space automatically detects and repairs data using the erasure coded parity shards."}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Automatic healing:"})," A background scanner continuously checks data integrity (bitrot detection) and repairs any inconsistencies automatically."]}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Manual healing:"})}),(0,s.jsx)(f,{children:"# Heal all objects in a bucket\ns3 admin heal hanzo/my-bucket --recursive\n\n# Heal a specific object\ns3 admin heal hanzo/my-bucket/important-file.dat\n\n# Heal the entire server\ns3 admin heal hanzo --recursive\n\n# Dry-run to see what would be healed\ns3 admin heal hanzo --recursive --dry-run\n\n# View healing status\ns3 admin heal hanzo --recursive --verbose"}),(0,s.jsxs)(x,{type:"info",children:["After replacing a failed drive, healing runs automatically to reconstruct the missing shards onto the new drive. The scanner speed can be adjusted with ",(0,s.jsx)("code",{style:y,children:"S3_SCANNER_SPEED"}),"."]}),(0,s.jsx)(_,{id:"ops-locking",children:"Object Locking / WORM"}),(0,s.jsx)(v,{children:"Object Locking enables Write-Once-Read-Many (WORM) compliance, preventing objects from being deleted or overwritten for a specified retention period. This is required for regulatory compliance (SEC 17a-4, FINRA, HIPAA)."}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Prerequisites:"})," Object locking must be enabled at bucket creation time and cannot be added later. Versioning is automatically enabled on locked buckets."]}),(0,s.jsx)(f,{title:"Create a locked bucket",children:"s3 mb hanzo/compliance-data --with-lock"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Retention modes:"})}),(0,s.jsx)(S,{headers:["Mode","Description"],rows:[["Governance","Users with s3:BypassGovernanceRetention permission can delete/modify objects before retention expires. Suitable for internal compliance."],["Compliance","No one \u2014 including root \u2014 can delete objects before retention expires. Irreversible. Required for strict regulatory compliance."]]}),(0,s.jsx)(f,{title:"Set default retention",children:"# Set 365-day governance retention on a bucket\ns3 retention set --default governance 365d hanzo/compliance-data\n\n# Set compliance retention on a specific object\ns3 retention set compliance 180d hanzo/compliance-data/audit-log.csv\n\n# View retention settings\ns3 retention info hanzo/compliance-data/audit-log.csv\n\n# Clear retention (governance mode only, with bypass permission)\ns3 retention clear --default hanzo/compliance-data"}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Legal Hold:"})," Independently of retention, a legal hold prevents deletion indefinitely until explicitly removed. Used for litigation hold requirements."]}),(0,s.jsx)(f,{children:"# Enable legal hold\ns3 legalhold set hanzo/compliance-data/document.pdf\n\n# Check legal hold status\ns3 legalhold info hanzo/compliance-data/document.pdf\n\n# Remove legal hold\ns3 legalhold clear hanzo/compliance-data/document.pdf"}),(0,s.jsx)(_,{id:"ops-metrics",children:"Metrics & Monitoring"}),(0,s.jsx)(v,{children:"Hanzo Space exposes Prometheus-compatible metrics for monitoring:"}),(0,s.jsx)(S,{headers:["Endpoint","Description"],rows:[["/minio/v2/metrics/cluster","Cluster-wide aggregated metrics"],["/minio/v2/metrics/node","Per-node metrics"],["/minio/v2/metrics/bucket","Per-bucket metrics"],["/minio/v2/metrics/resource","Resource utilization metrics"]]}),(0,s.jsx)(f,{title:"Generate Prometheus config",children:"# Auto-generate prometheus.yml scrape config\ns3 admin prometheus generate hanzo\n\n# Or configure manually in prometheus.yml:\n# scrape_configs:\n#   - job_name: hanzo-storage\n#     metrics_path: /minio/v2/metrics/cluster\n#     bearer_token: <s3 admin prometheus generate output>\n#     static_configs:\n#       - targets: ['storage.example.com:9000']"}),(0,s.jsx)(v,{children:"For public access to metrics (no auth required):"}),(0,s.jsx)(f,{children:"S3_PROMETHEUS_AUTH_TYPE=public"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Key metrics:"})}),(0,s.jsx)(S,{headers:["Metric","Description"],rows:[["minio_node_disk_total_bytes","Total disk capacity"],["minio_node_disk_used_bytes","Used disk space"],["minio_node_disk_free_bytes","Free disk space"],["minio_s3_requests_total","Total S3 requests by API and status"],["minio_s3_requests_errors_total","Failed S3 requests"],["minio_s3_traffic_received_bytes","Total bytes received"],["minio_s3_traffic_sent_bytes","Total bytes sent"],["minio_bucket_objects_count","Number of objects per bucket"],["minio_bucket_usage_total_bytes","Total size per bucket"],["minio_cluster_nodes_online_total","Number of online nodes"],["minio_cluster_nodes_offline_total","Number of offline nodes"],["minio_cluster_disk_online_total","Number of online drives"],["minio_cluster_disk_offline_total","Number of offline drives"],["minio_heal_objects_total","Objects healed"],["minio_node_scanner_objects_scanned","Objects scanned for bitrot"]]}),(0,s.jsxs)(x,{type:"tip",children:["Grafana dashboards are available at ",(0,s.jsx)("strong",{style:{color:r},children:"https://grafana.com/grafana/dashboards/13502"})," (cluster overview) and ",(0,s.jsx)("strong",{style:{color:r},children:"13503"})," (bucket metrics)."]}),(0,s.jsx)(_,{id:"ops-tls",children:"TLS / Network Encryption"}),(0,s.jsx)(v,{children:"Enable TLS for encryption in transit. Hanzo Space auto-detects TLS certificates:"}),(0,s.jsx)(f,{title:"Certificate paths",children:"~/.s3/certs/\n\u251c\u2500\u2500 public.crt    # Server certificate (PEM)\n\u251c\u2500\u2500 private.key   # Server private key (PEM)\n\u2514\u2500\u2500 CAs/          # Trusted CA certificates (optional)\n    \u2514\u2500\u2500 ca.crt"}),(0,s.jsx)(v,{children:"The server automatically uses HTTPS when certificates are present. For Kubernetes, mount TLS secrets:"}),(0,s.jsx)(f,{title:"K8s TLS secret mount",children:"volumes:\n  - name: tls-certs\n    secret:\n      secretName: storage-tls\n      items:\n        - key: tls.crt\n          path: public.crt\n        - key: tls.key\n          path: private.key\ncontainers:\n  - name: storage\n    volumeMounts:\n      - name: tls-certs\n        mountPath: /root/.s3/certs\n        readOnly: true"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Let's Encrypt with cert-manager:"})}),(0,s.jsx)(f,{children:"apiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: storage-tls\nspec:\n  secretName: storage-tls\n  issuerRef:\n    name: letsencrypt-prod\n    kind: ClusterIssuer\n  dnsNames:\n    - s3.example.com\n    - console.example.com"}),(0,s.jsx)(x,{type:"warning",children:"For distributed deployments, all nodes must use the same TLS certificates or certificates from the same CA. Clients must trust the CA that signed the server certificates."}),(0,s.jsx)(_,{id:"ops-scaling",children:"Scaling & Expansion"}),(0,s.jsx)(v,{children:"Expand storage capacity by adding new server pools to an existing deployment. The original data stays on the existing pool; new data is distributed across all pools."}),(0,s.jsx)(f,{title:"Add a new server pool",children:"# Original 4-node cluster\ns3 server http://node{1...4}.example.com/data{1...4}\n\n# Expand with 4 more nodes (add to the same command)\ns3 server \\\n  http://node{1...4}.example.com/data{1...4} \\\n  http://node{5...8}.example.com/data{1...4}"}),(0,s.jsxs)(v,{children:[(0,s.jsx)("strong",{style:{color:r},children:"Decommissioning"})," \u2014 Safely remove a server pool by migrating its data:"]}),(0,s.jsx)(f,{children:"# Start decommissioning a pool\ns3 admin decommission start hanzo http://node{1...4}.example.com/data{1...4}\n\n# Check decommission status\ns3 admin decommission status hanzo\n\n# Cancel decommission (if needed)\ns3 admin decommission cancel hanzo http://node{1...4}.example.com/data{1...4}"}),(0,s.jsx)(x,{type:"info",children:"Decommissioning migrates all data from the old pool to the remaining pools. The cluster stays online and serves requests during migration. Do not remove nodes until decommissioning completes."}),(0,s.jsx)(_,{id:"ops-upgrade",children:"Upgrade Procedures"}),(0,s.jsx)(v,{children:"Hanzo Space supports zero-downtime rolling upgrades for distributed deployments:"}),(0,s.jsx)(f,{title:"Binary upgrade",children:"# 1. Download new binary\nwget https://github.com/hanzoai/storage/releases/latest/download/s3-linux-amd64\n\n# 2. Stop the service\nsudo systemctl stop hanzo-storage\n\n# 3. Replace binary\nchmod +x s3-linux-amd64\nsudo mv s3-linux-amd64 /usr/local/bin/s3\n\n# 4. Start the service\nsudo systemctl start hanzo-storage\n\n# 5. Verify\ns3 admin info hanzo"}),(0,s.jsx)(f,{title:"Docker upgrade",children:'# Pull latest image\ndocker pull ghcr.io/hanzoai/storage:latest\n\n# Restart container\ndocker stop hanzo-space\ndocker rm hanzo-space\ndocker run -d --name hanzo-space \\\n  -p 9000:9000 -p 9001:9001 \\\n  -e S3_ROOT_USER=admin \\\n  -e S3_ROOT_PASSWORD=changeme123 \\\n  -v /data:/data \\\n  ghcr.io/hanzoai/storage:latest \\\n  server /data --console-address ":9001"'}),(0,s.jsx)(f,{title:"Kubernetes upgrade",children:"# Update image\nkubectl -n storage set image deployment/storage storage=ghcr.io/hanzoai/storage:latest\n\n# Or restart to pull :latest\nkubectl -n storage rollout restart deployment/storage\n\n# Monitor rollout\nkubectl -n storage rollout status deployment/storage"}),(0,s.jsx)(x,{type:"warning",children:"For distributed deployments, upgrade one node at a time and verify cluster health between each. The cluster can serve requests with reduced capacity during rolling upgrades."}),(0,s.jsx)(_,{id:"ops-batch",children:"Batch Operations"}),(0,s.jsx)(v,{children:"The batch framework enables bulk operations on objects using declarative YAML job files:"}),(0,s.jsx)(f,{title:"Batch replicate",children:'# batch-replicate.yaml\nreplicate:\n  apiVersion: v1\n  source:\n    type: s3\n    bucket: source-bucket\n    prefix: data/\n  target:\n    type: s3\n    bucket: target-bucket\n    endpoint: https://remote.example.com\n    credentials:\n      accessKey: REMOTE_ACCESS_KEY\n      secretKey: REMOTE_SECRET_KEY\n  flags:\n    filter:\n      newerThan: "7d"\n      olderThan: "0d"\n    notify:\n      endpoint: https://hooks.example.com/batch\n      token: my-webhook-token'}),(0,s.jsx)(f,{title:"Batch key rotation",children:'# batch-keyrotate.yaml\nkeyrotate:\n  apiVersion: v1\n  bucket: secure-data\n  prefix: ""\n  encryption:\n    type: sse-s3\n  flags:\n    filter:\n      newerThan: "0d"\n    notify:\n      endpoint: https://hooks.example.com/batch\n      token: my-webhook-token'}),(0,s.jsx)(f,{title:"Run batch jobs",children:"# Start a batch job\ns3 batch start hanzo batch-replicate.yaml\n\n# List running jobs\ns3 batch list hanzo\n\n# Check job status\ns3 batch status hanzo JOB_ID\n\n# Cancel a job\ns3 batch cancel hanzo JOB_ID"}),(0,s.jsx)(_,{id:"ops-recovery",children:"Data Recovery"}),(0,s.jsx)(v,{children:"Recovery procedures depend on the failure type:"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Single drive failure (erasure coded):"})}),(0,s.jsx)(f,{children:"# 1. Replace the failed drive with a new one (same mount point)\n# 2. Healing starts automatically\n# 3. Monitor healing progress\ns3 admin heal hanzo --recursive --verbose"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Single node failure (distributed):"})}),(0,s.jsx)(f,{children:"# 1. The cluster continues serving requests (if quorum is maintained)\n# 2. Replace/repair the node\n# 3. Start the storage server with the same configuration\n# 4. Healing reconstructs missing data automatically"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Full cluster recovery from replication:"})}),(0,s.jsx)(f,{children:"# If site replication is configured, the surviving site has all data.\n# Deploy a new cluster and add it as a replication peer:\ns3 admin replicate add surviving-site new-site\n\n# Data syncs automatically from the surviving site."}),(0,s.jsxs)(x,{type:"warning",children:["For single-drive, single-node deployments, there is no built-in redundancy. Use regular backups with ",(0,s.jsx)("code",{style:y,children:"s3 mirror"})," to protect against data loss."]}),(0,s.jsx)(f,{title:"Backup with s3 mirror",children:"# Full backup to another server\ns3 mirror hanzo/my-bucket backup/my-bucket\n\n# Incremental backup (only changed objects)\ns3 mirror --watch hanzo/my-bucket backup/my-bucket"}),(0,s.jsx)(_,{id:"ops-troubleshooting",children:"Troubleshooting"}),(0,s.jsx)(v,{children:"Common issues and solutions:"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Server won't start:"})}),(0,s.jsx)(f,{children:"# Check logs\njournalctl -u hanzo-storage -f\n\n# Common causes:\n# - Port already in use: check with 'lsof -i :9000'\n# - Drive permissions: ensure s3 user owns data directories\n# - Invalid credentials: S3_ROOT_USER min 3 chars, PASSWORD min 8 chars"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Drive offline:"})}),(0,s.jsx)(f,{children:"# Check drive health\ns3 admin info hanzo --json | jq '.info.backend'\n\n# Check disk usage\ns3 admin info hanzo\n\n# Force heal if automatic healing is stalled\ns3 admin heal hanzo --recursive --force-start"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Slow performance:"})}),(0,s.jsx)(f,{children:"# Check active connections and requests\ns3 admin trace hanzo --verbose\n\n# Check network bandwidth\ns3 admin speedtest hanzo\n\n# Check drive I/O performance\ns3 admin speedtest hanzo --drive\n\n# Tune scanner speed for less background I/O\ns3 admin config set hanzo scanner speed=slow"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Authentication errors:"})}),(0,s.jsx)(f,{children:"# Verify OIDC config\ns3 admin config get hanzo identity_openid\n\n# Check access key permissions\ns3 admin user info hanzo USERNAME\n\n# Verify bucket policy\ns3 anonymous get hanzo/my-bucket\n\n# Debug S3 request signatures\ns3 admin trace hanzo --call s3 --verbose"}),(0,s.jsx)(v,{children:(0,s.jsx)("strong",{style:{color:r},children:"Replication lag:"})}),(0,s.jsx)(f,{children:"# Check replication backlog\ns3 replicate backlog hanzo/my-bucket\n\n# Check replication status\ns3 replicate status hanzo/my-bucket\n\n# Force resync\ns3 replicate resync start hanzo/my-bucket"}),(0,s.jsx)(_,{id:"ops-healthcheck",children:"Health Check API"}),(0,s.jsx)(v,{children:"Built-in health check endpoints for monitoring and load balancer integration:"}),(0,s.jsx)(S,{headers:["Endpoint","Method","Description"],rows:[["/minio/health/live","GET","Returns 200 if the server process is running. Use as a liveness probe."],["/minio/health/ready","GET","Returns 200 if the server is ready to accept requests. Use as a readiness probe."],["/minio/health/cluster","GET","Returns 200 if the cluster has write quorum. Use for load balancer health checks."],["/minio/health/cluster?maintenance=true","GET","Returns 200 if cluster can tolerate one node going down. Use before maintenance."]]}),(0,s.jsx)(f,{title:"Docker healthcheck",children:'healthcheck:\n  test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]\n  interval: 30s\n  timeout: 5s\n  retries: 3\n  start_period: 30s'}),(0,s.jsx)(f,{title:"Kubernetes probes",children:"readinessProbe:\n  httpGet:\n    path: /minio/health/ready\n    port: 9000\n  initialDelaySeconds: 10\n  periodSeconds: 10\nlivenessProbe:\n  httpGet:\n    path: /minio/health/live\n    port: 9000\n  initialDelaySeconds: 30\n  periodSeconds: 30\nstartupProbe:\n  httpGet:\n    path: /minio/health/live\n    port: 9000\n  failureThreshold: 30\n  periodSeconds: 10"})]}),T=()=>{const[e,n]=(0,i.useState)(window.location.hash.replace(/^#/,""));return(0,i.useEffect)((()=>{const e=e=>{const n=e.target.closest("a");if(!n)return;const t=n.getAttribute("href");if(t&&t.startsWith("#")){var i;e.preventDefault();const n=t.slice(1);window.history.replaceState(null,"",`/docs#${n}`),null===(i=document.getElementById(n))||void 0===i||i.scrollIntoView({behavior:"smooth"})}};return document.addEventListener("click",e),()=>document.removeEventListener("click",e)}),[]),(0,i.useEffect)((()=>{const e=()=>{const e=window.location.hash.replace(/^#/,"").replace(/\.html$/,"").replace(/\/$/,"");if(!e)return;var t;if(document.getElementById(e))return null===(t=document.getElementById(e))||void 0===t||t.scrollIntoView({behavior:"smooth"}),void n(e);const i=E[e];var s;if(i&&document.getElementById(i))return window.history.replaceState(null,"",`#${i}`),null===(s=document.getElementById(i))||void 0===s||s.scrollIntoView({behavior:"smooth"}),void n(i);const o=e.split("/");for(let r=o.length;r>0;r--){const e=o.slice(0,r).join("/"),t=E[e];var a;if(t&&document.getElementById(t))return window.history.replaceState(null,"",`#${t}`),null===(a=document.getElementById(t))||void 0===a||a.scrollIntoView({behavior:"smooth"}),void n(t)}};return e(),window.addEventListener("hashchange",e),()=>window.removeEventListener("hashchange",e)}),[]),(0,s.jsxs)("div",{style:{minHeight:"100vh",backgroundColor:o,color:r,fontFamily:m,WebkitFontSmoothing:"antialiased"},children:[(0,s.jsx)("nav",{style:{position:"sticky",top:0,zIndex:50,backgroundColor:"rgba(9, 9, 11, 0.85)",backdropFilter:"blur(16px)",WebkitBackdropFilter:"blur(16px)",borderBottom:`1px solid ${u}`},children:(0,s.jsxs)("div",{style:{maxWidth:1200,margin:"0 auto",padding:"0 24px",height:56,display:"flex",alignItems:"center",justifyContent:"space-between"},children:[(0,s.jsxs)("a",{href:"/login",style:{display:"flex",alignItems:"center",gap:10,textDecoration:"none",color:r},children:[(0,s.jsx)(b,{size:24}),(0,s.jsx)("span",{style:{fontSize:15,fontWeight:600,letterSpacing:"-0.02em"},children:"Hanzo Space"}),(0,s.jsx)("span",{style:{fontSize:12,color:l,marginLeft:4},children:"Docs"})]}),(0,s.jsxs)("div",{style:{display:"flex",alignItems:"center",gap:16},children:[(0,s.jsx)("a",{href:"/login",style:{color:c,textDecoration:"none",fontSize:13,fontWeight:500},children:"Home"}),(0,s.jsx)("a",{href:"/login",style:{backgroundColor:r,color:o,border:"none",borderRadius:8,padding:"8px 18px",fontSize:13,fontWeight:600,textDecoration:"none"},children:"Sign In"})]})]})}),(0,s.jsxs)("div",{style:{maxWidth:1200,margin:"0 auto",display:"flex",minHeight:"calc(100vh - 56px)"},children:[(0,s.jsx)("aside",{style:{width:220,flexShrink:0,padding:"32px 0 64px 24px",borderRight:`1px solid ${u}`,position:"sticky",top:56,height:"calc(100vh - 56px)",overflowY:"auto"},children:w.map(((t,i)=>{const o=t.items.map((e=>e.id)).includes(e);return(0,s.jsxs)("div",{style:{marginBottom:20,paddingBottom:i<w.length-1?16:0,borderBottom:i<w.length-1?`1px solid ${u}`:"none"},children:[(0,s.jsx)("div",{style:{fontSize:11,fontWeight:700,color:o?r:l,textTransform:"uppercase",letterSpacing:"0.06em",marginBottom:8,transition:"color 0.15s"},children:t.title}),t.items.map((t=>{const i=e===t.id;return(0,s.jsx)("a",{href:`#${t.id}`,onClick:()=>n(t.id),style:{display:"block",padding:"5px 12px",fontSize:13,color:i?r:c,textDecoration:"none",borderRadius:6,lineHeight:1.5,backgroundColor:i?"rgba(255,255,255,0.06)":"transparent",borderLeft:i?`2px solid ${d}`:"2px solid transparent",transition:"all 0.15s"},onMouseEnter:e=>{i||(e.currentTarget.style.color=r,e.currentTarget.style.backgroundColor="rgba(255,255,255,0.04)")},onMouseLeave:e=>{i||(e.currentTarget.style.color=c,e.currentTarget.style.backgroundColor="transparent")},children:t.label},t.id)}))]},t.title)}))}),(0,s.jsxs)("main",{style:{flex:1,padding:"32px 48px 96px",maxWidth:800,minWidth:0},children:[(0,s.jsx)("h1",{style:{fontSize:32,fontWeight:700,letterSpacing:"-0.035em",margin:"0 0 8px"},children:"Hanzo Space Documentation"}),(0,s.jsx)("p",{style:{fontSize:15,color:l,margin:"0 0 8px",lineHeight:1.6},children:"S3-compatible object storage. Deploy anywhere, use any AWS S3 SDK, CLI, or integration."}),(0,s.jsx)("p",{style:{fontSize:12,color:l,margin:"0 0 32px",letterSpacing:"0.01em"},children:"7 sections \xb7 40+ topics"}),(0,s.jsxs)("div",{style:{backgroundColor:a,borderRadius:12,padding:"24px 28px",marginBottom:32,borderLeft:`3px solid ${d}`,boxShadow:`0 0 24px ${h}`},children:[(0,s.jsx)("h3",{style:{fontSize:14,fontWeight:600,margin:"0 0 12px",letterSpacing:"-0.01em"},children:"Quick Connect"}),(0,s.jsx)(f,{children:"# Configure s3 CLI\ns3 alias set hanzo https://s3.hanzo.ai ACCESS_KEY SECRET_KEY\n\n# Or use AWS CLI\naws configure set default.s3.endpoint_url https://s3.hanzo.ai\naws s3 ls\n\n# JavaScript\nimport { S3Client } from 'hanzo-s3'\nconst client = new S3Client({\n  endPoint: 's3.hanzo.ai',\n  useSSL: true,\n  accessKey: 'YOUR_ACCESS_KEY',\n  secretKey: 'YOUR_SECRET_KEY',\n})"})]}),(0,s.jsx)(O,{})]})]})]})}}}]);
//# sourceMappingURL=610.e7a5e28a.chunk.js.map